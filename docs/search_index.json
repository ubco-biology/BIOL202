[["index.html", "Tutorials for BIOL202: Introduction to Biostatistics Welcome", " Tutorials for BIOL202: Introduction to Biostatistics Jason Pither 2021-07-13 Welcome This is an open source online book that includes all tutorials and other resources for the “lab” portion of the course BIOL202: Introduction to Biostatistics, at the University of British Columbia, Okanagan campus. This book is continually being updated, so be sure to refresh your browser each time you visit. "],["author.html", "Author", " Author Jason Pither is an Associate Professor in the Department of Biology at the Okanagan campus of the University of British Columbia. He is an ecologist with interests in biogeography, community ecology, and landscape ecology. He has been using “R” (and its predecessor, “S”) in his research for over two decades, and has been teaching Introductory Biostatistics using R since 2014. "],["acknowledgments.html", "Acknowledgments", " Acknowledgments This online book borrows materials generously made openly available by the following keen educators: Yaniv Brandvain (Applied Biostats online book) Chester Ismay and Albert Y. Kim (Statistical Inference via Data Science online book) Mike Whitlock and Dolph Schluter (resources accompanying the text “Analysis of Biological Data”) "],["copyright.html", "Copyright", " Copyright This work is licenced under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) Please use the following for citing this document Pither, J. (2021). Tutorials for BIOL202: Introduction to Biostatistics. https://ubco-biology.github.io/BIOL202/index.html All source files are available at this website: https://github.com/ubco-biology/BIOL202. "],["conventions.html", "Conventions", " Conventions "],["data-import.html", "Chapter 1 Importing Data", " Chapter 1 Importing Data Minor updates on July 13, 2021 concerning read_csv versus read.csv. "],["getting-started.html", "1.1 Getting started", " 1.1 Getting started In this tutorial you will learn how to: Format your data for importing into R Tidy data Do’s and Don’ts of naming variables and data entry Wide versus Long format Saving your file in CSV (comma-separated values) format Import your CSV file into a data frame in R "],["packages.html", "1.2 Packages", " 1.2 Packages For this tutorial you’ll need the tidyverse package (and the many packages it brings with it), and the dlookr package. Install these if you haven’t already done so on your computer. Load the libraries library(tidyverse) library(dlookr) "],["tidy-data.html", "1.3 Tidy data", " 1.3 Tidy data Read this recent article describing why making your data “tidy” saves a lot of time and effort in the long run. Oh, and it uses Covid-19 data to demonstrate! Optional: If you’d like a longer, more in-depth read about “tidy data,” see Hadley Wickham’s “R for Datascience” online book, linked here You can tidy your data using the functionality of the dplyr package, which comes with the tidyverse package. Its associated cheatsheet is available here. 1.3.1 Naming variables The following are good rules of thumb to follow when setting up your spreadsheet to store your data: the first row should contain the names of the variables each variable should have its own column below the “header” row that contains the variable names, each row should contain one observation do not mix data types (e.g. numerical, categorical) within a single column; the variable names should not include spaces or special characters; in lieu of a space, use an underscore \"_\" use easily-interpreted variable names when possible, and provide a separate “.txt” file that describes what each variable is, including units (this file is called a “data dictionary”) the data file should be saved in “CSV” format do not include spaces or special characters in the file name "],["preparing-the-data-for-import.html", "1.4 Preparing the data for import", " 1.4 Preparing the data for import Below is a screenshot of an Excel worksheet that a student might have generated during a concentration-response exercise, conducted in a lab course. You’ll see three sets of data, one for each substance being analyzed (NaCl, Sucrose, and CaCl2), some calculated statistics associated with the measured values (mean and standard error of the mean), and finally some response curves that have been fit using Excel (yuk!). We need to re-format these data (i.e. make them “tidy”) in order to import into R. Typically it is easier to enter data in “wide” format, so we’ll assume this is the case here. Below is a snapshop of how the data in the above spreadsheet might be organized for import into R: Note that we don’t include any derived values like the mean and standard deviation… these will be calculated in R. "],["importing-data-from-a-csv-file.html", "1.5 Importing data from a CSV file", " 1.5 Importing data from a CSV file You can find additional help on importing different types of files here, and the using the Data Import Cheat Sheet. Let’s get some data to work with. We have created a CSV file with data formatted as shown above. First, be sure to set your working directory to the same place that your markdown file is in (you should have a markdown file that you use when working through tutorials). We’re going to cheat here a bit, and you’re going to use the menu in RStudio to do this: Select the “session” menu Select “Set working directory,” and then select “to source file location.” Now we can download the CSV file by right-clicking on this link here, and saving the file to your working directory. NOTE: If your spreadsheet includes blank cells (i.e. missing values), R will automatically covert these to “NA” values. Once it is saved in your working directory, we use the read_csv function from the readr package (which came with the tidyverse package) to import the data. We’ll import it into a tibble called “example.data”: example.data &lt;- read_csv(file = &quot;./data/example_data.csv&quot;) ## ## ── Column specification ─────────────────────────────────────────────────────────────────────────────────────────── ## cols( ## substance = col_character(), ## conc = col_double(), ## rep1 = col_double(), ## rep2 = col_double(), ## rep3 = col_double(), ## rep4 = col_double(), ## rep5 = col_double() ## ) NOTE: if the preceding code does not work for you, use this code instead: example.data &lt;- read_csv(file.choose()) in which case R will let you choose the file using point-and-click. NOTE: The base R package includes the read.csv function, which works similarly to the read_csv function, but is a bit less straightforward, hence our preference for read_csv. Now we can have a look at the data frame, exploring its structure using the diagnose function from the dlookr package, then looking at the first few rows with the head function: dlookr::diagnose(example.data) ## # A tibble: 7 x 6 ## variables types missing_count missing_percent unique_count unique_rate ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 substance character 0 0 3 0.143 ## 2 conc numeric 0 0 7 0.333 ## 3 rep1 numeric 0 0 17 0.810 ## 4 rep2 numeric 0 0 19 0.905 ## 5 rep3 numeric 0 0 20 0.952 ## 6 rep4 numeric 0 0 16 0.762 ## 7 rep5 numeric 0 0 20 0.952 and: head(example.data) ## # A tibble: 6 x 7 ## substance conc rep1 rep2 rep3 rep4 rep5 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 NaCl 300 97.4 97.3 98.4 93 91.2 ## 2 NaCl 250 97.3 97.9 96.9 92.1 95.8 ## 3 NaCl 200 96.2 93.8 97.3 91.7 93.9 ## 4 NaCl 150 94.8 93.4 95.4 90.6 95.1 ## 5 NaCl 100 10 29.5 11.1 17.7 16.9 ## 6 NaCl 50 0.7 1.1 5.9 6.2 1.6 "],["exporting-or-writing-data-to-a-csv-file.html", "1.6 Exporting or “writing” data to a CSV file", " 1.6 Exporting or “writing” data to a CSV file Perhaps we wish to export a tibble or dataframe from R to a CSV file. We can do this with the write_csv function: ?write_csv Here we write to a file called “exampledata.csv”: write_csv(example.data, &quot;./output/exampledata.csv&quot;) NOTE: The base R package includes the write.csv function, which works similarly to the read_csv function, but is a bit less straightforward, hence our preference for write_csv. ALL MATERIAL BELOW HERE IS OPTIONAL AND STILL UNDER CONSTRUCTION "],["converting-from-wide-to-long-format.html", "1.7 Converting from wide to long format", " 1.7 Converting from wide to long format We’ll use the gather function for this: ?gather Here’s the appropriate code for our current example, and we’ll create a new data frame called “long.data”: long.data &lt;- gather(example.data, replicate, value, rep1:rep5, factor_key = TRUE) Now let’s look at the resulting data frame: head(long.data) ## # A tibble: 6 x 4 ## substance conc replicate value ## &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 NaCl 300 rep1 97.4 ## 2 NaCl 250 rep1 97.3 ## 3 NaCl 200 rep1 96.2 ## 4 NaCl 150 rep1 94.8 ## 5 NaCl 100 rep1 10 ## 6 NaCl 50 rep1 0.7 We could now do some analyses on these data, as shown in the next section. "],["example-analyses-on-long-format-data.html", "1.8 Example analyses on long format data", " 1.8 Example analyses on long format data As we learned in another tutorial, we can calculate descriptive statistics (e.g. mean, standard deviation) for a numeric variable grouped by categories. In the present example, we may wish to calculate the mean and standard deviation for each combination of concentration and substance. Here we provide the mean and standard deviation of value grouped according to conc and substance: long.data %&gt;% group_by(conc, substance) %&gt;% summarize(mean_val = mean(value, na.rm = TRUE), sd_val = sd(value, na.rm = T)) ## `summarise()` has grouped output by &#39;conc&#39;. You can override using the `.groups` argument. ## # A tibble: 21 x 4 ## # Groups: conc [7] ## conc substance mean_val sd_val ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 CaCl2 0.56 0.261 ## 2 0 NaCl 0.74 0.503 ## 3 0 Sucrose 0.44 0.230 ## 4 50 CaCl2 1.14 1.06 ## 5 50 NaCl 3.1 2.71 ## 6 50 Sucrose 0.66 0.230 ## 7 100 CaCl2 92.4 1.70 ## 8 100 NaCl 17.0 7.75 ## 9 100 Sucrose 0.86 0.385 ## 10 150 CaCl2 93.4 0.986 ## # … with 11 more rows The output is a tibble (see R for Data Science book). 1.8.1 Standard error by group To calculate the standard error of value, grouped by each combination of conc (concentration) and substance, we need to do a bit more work. We first our own standard error function, then use the dplyr package to apply the function across the group combinations. First, create a function for the standard error (consult this tutorial): standard.error &lt;- function(x){sd(na.omit(x))/sqrt(length(na.omit(x)))} Now we can apply this function to the group combinations using this code: long.data %&gt;% group_by(conc, substance) %&gt;% summarize(mean_trans = mean(value, na.rm = TRUE), st_err = standard.error(value)) ## `summarise()` has grouped output by &#39;conc&#39;. You can override using the `.groups` argument. ## # A tibble: 21 x 4 ## # Groups: conc [7] ## conc substance mean_trans st_err ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 CaCl2 0.56 0.117 ## 2 0 NaCl 0.74 0.225 ## 3 0 Sucrose 0.44 0.103 ## 4 50 CaCl2 1.14 0.476 ## 5 50 NaCl 3.1 1.21 ## 6 50 Sucrose 0.66 0.103 ## 7 100 CaCl2 92.4 0.76 ## 8 100 NaCl 17.0 3.47 ## 9 100 Sucrose 0.86 0.172 ## 10 150 CaCl2 93.4 0.441 ## # … with 11 more rows "],["converting-from-long-to-wide-format.html", "1.9 Converting from long to wide format", " 1.9 Converting from long to wide format To be completed In the meantime, consult this page where it uses tidyr for this purpose. "],["the-expand-grid-function.html", "1.10 The “expand.grid” function", " 1.10 The “expand.grid” function TIP You can easily create a long-format data frame in R using the expand.grid function: ?expand.grid For the above example dataset, we could have prepared a data frame in R with the appropriate long format as follows: long.data2 &lt;- as.data.frame(expand.grid( conc = seq(from = 300, to = 0, by = -50), substance = c(&quot;NaCl&quot;, &quot;Sucrose&quot;, &quot;CaCl2&quot;), replicate = c(&quot;rep1&quot;, &quot;rep2&quot;, &quot;rep3&quot;, &quot;rep4&quot;, &quot;rep5&quot;), value = NA)) The result: head(long.data2) ## conc substance replicate value ## 1 300 NaCl rep1 NA ## 2 250 NaCl rep1 NA ## 3 200 NaCl rep1 NA ## 4 150 NaCl rep1 NA ## 5 100 NaCl rep1 NA ## 6 50 NaCl rep1 NA We can re-order the columns to look exactly like the original data frame, here using old-school syntax: long.data2 &lt;- long.data2[,c(&quot;substance&quot;,&quot;conc&quot;,&quot;replicate&quot;,&quot;value&quot;)] Or here using “tidy” syntax and the relocate function from dplyr: long.data2 &lt;- long.data2 %&gt;% dplyr::relocate(substance) The result: head(long.data2) ## substance conc replicate value ## 1 NaCl 300 rep1 NA ## 2 NaCl 250 rep1 NA ## 3 NaCl 200 rep1 NA ## 4 NaCl 150 rep1 NA ## 5 NaCl 100 rep1 NA ## 6 NaCl 50 rep1 NA If you wished to use the long format data frame created above say, for example, to enter data, you could export it to CSV first, open it in Excel, then enter your measurements under the “value” column. Expore the data frame with the write.csv command: ?write.csv write.csv(long.data2, file = &quot;./output/longdata.csv&quot;, row.names = FALSE) "],["vis-describe.html", "Chapter 2 Visualizing and describing a single variable", " Chapter 2 Visualizing and describing a single variable This page was last updated on July 13, 2021. "],["background.html", "2.1 Background", " 2.1 Background When visualizing a describing a single variable, we typically wish to describe a frequency distribution. We visualize a frequency distribution in different ways depending on the type of variable we’re dealing with: categorical or numeric. If the variable is categorical, we can visualize the frequency distribution using a bar chart If the variable is numeric, we visualize the frequency distribution using a histogram In this tutorial you’ll learn to construct and interpret each of these types of visualization. You’ll also learn to calculate some descriptive statistics. "],["getting-started-1.html", "2.2 Getting started", " 2.2 Getting started 2.2.1 Load the required packages In this tutorial we will make use of the following R packages: tidyverse skimr janitor naniar library(janitor) library(skimr) library(tidyverse) library(naniar) 2.2.2 Import the data We will use the following datasets in this tutorial: the students.csv file contains anonymous physical data about BIOL202 students from a few years ago the birds.csv file contains counts of different categories of bird from a marsh habitat Read in the data from a website (hence the url function wrapped in the read.csv function): students &lt;- read.csv(url(&quot;https://people.ok.ubc.ca/jpither/datasets/students.csv&quot;), header = TRUE) birds &lt;- read.csv(url(&quot;https://people.ok.ubc.ca/jpither/datasets/birds.csv&quot;), header = TRUE) TIP: Notice the two sets of parentheses in each line of code above. The RStudio text editor will highlight errors such as unmatched parentheses for you. 2.2.3 Get an overview of the data The students object that we created in your workspace is a data frame, with each row representing a case and each column representing a variable. Data frames can store a mixture of data types: numeric variables, categorical variables, logical variables etc… all in the same data frame (as separate columns). This isn’t the case with other object types (e.g. matrices). In other tutorials we’ll also use “tibbles,” which are better versions of data frames, and are part of the “tidyverse.” But that’s for later. To view the names of the variables in the data frame, use the names command as follows: names(students) ## [1] &quot;height_cm&quot; &quot;head_circum_cm&quot; &quot;number_siblings&quot; &quot;dominant_hand&quot; &quot;dominant_foot&quot; &quot;dominant_eye&quot; This returns the names height_cm, head_circum_cm, number_siblings, dominant_hand, dominant_foot, and dominant_eye. We can get a glimpse of the first handful of cases (rows) of our data with the head function: head(students) ## height_cm head_circum_cm number_siblings dominant_hand dominant_foot dominant_eye ## 1 160.02 55 1 r r l ## 2 180.00 56 1 r r r ## 3 192.00 56 5 r r r ## 4 165.00 61 2 r r r ## 5 182.00 61 1 r l r ## 6 165.00 53 1 r r l or with the glimpse function from the dplyr package: glimpse(students) ## Rows: 154 ## Columns: 6 ## $ height_cm &lt;dbl&gt; 160.02, 180.00, 192.00, 165.00, 182.00, 165.00, 165.10, 163.00, 155.00, 176.00, 162.30, 1… ## $ head_circum_cm &lt;dbl&gt; 55.0, 56.0, 56.0, 61.0, 61.0, 53.0, 53.5, 54.0, 54.0, 54.0, 54.0, 54.3, 54.5, 54.5, 54.5,… ## $ number_siblings &lt;int&gt; 1, 1, 5, 2, 1, 1, 1, 0, 3, 1, 2, 1, 1, 1, 1, 3, 0, 1, 2, 1, 1, 0, 2, 3, 2, 1, 2, 2, 1, 1,… ## $ dominant_hand &lt;chr&gt; &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;,… ## $ dominant_foot &lt;chr&gt; &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;,… ## $ dominant_eye &lt;chr&gt; &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;l&quot;, &quot;r&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;,… You could also look at all of the data frame at once by typing its name into the console and pressing return, but that is not advisable, as you could get reams of output thrown at you if you’re dealing with a large dataset! It’s better to take a small peek at the data with head or glimpse. We should now get an idea of how many cases are there in this data set, how many variables it contains, and what type of data comprise each variable (e.g. numeric, integer, character, factor, logical, etc…). Use the skim function from the skimr package to do this: skim(students) (#tab:show_structure)Data summary Name students Number of rows 154 Number of columns 6 _______________________ Column type frequency: character 3 numeric 3 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace dominant_hand 0 1 1 1 0 2 0 dominant_foot 0 1 1 1 0 2 0 dominant_eye 0 1 1 1 0 2 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist height_cm 0 1 171.97 10.03 150 165 171.48 180.0 210.8 ▃▇▇▁▁ head_circum_cm 0 1 57.19 1.88 53 56 57.00 58.5 63.0 ▅▇▇▂▁ number_siblings 0 1 1.71 1.05 0 1 2.00 2.0 6.0 ▇▆▂▁▁ You see that there are: 154 rows (cases or records) and 6 columns (variables) 3 character (categorical) and 3 numerical variables (under the “Column Type Frequency” heading) no designated “group” variables There’s a lot of additional information, the most important of which is: “n_unique” tells you how many unique categories there are in each of the character (categorical) variables “n_missing” tells you if there are any missing values (typically coded as “NA”) for each variable Then it provides some descriptive stats for each of the categorical and numerical variables, including a miniature histogram for each of the numerical variables (you’ll learn about histograms shortly!). You should now repeat the preceding steps on the birds data frame, so you know what it looks like. Now that we have explored the basic structure of our dataset, we’re ready to start visualizing the data graphically! "],["frequency-distributions.html", "2.3 Frequency distributions", " 2.3 Frequency distributions Once you have a dataframe to work with, and have explored its structure and contents (above), the next order of business is always to visualize and summarize your data using graphs and tables. We start by examining the frequency distribution of the variable(s) of interest. A frequency distribution displays the number of occurrences (cases) of all values in the data. How we display this information depends on the type of data at hand: are they numerical or categorical? We also typically report the relative frequency distribution for the variable(s), which describes the fraction of occurrences of each value of a variable. Frequency distributions can be displayed in a table and graphically. "],["visualizing-and-describing-categorical-data.html", "2.4 Visualizing and describing categorical data", " 2.4 Visualizing and describing categorical data 2.4.1 Creating a frequency table for one categorical variable Use the xtabs command (from the base stats package) to produce a frequency table, which shows the frequency distribution for a categorical variable in tabular format. We’ll assign the output of the xtabs function to an object called dom.eye.freq. Here we show the frequency of observations in each of the two categories contained in the dominant_eye variable within the students dataframe. We first run the function and assign the output to an object dom.eye.freq, then type the name of the object to show its contents: dom.eye.freq &lt;- xtabs(~ dominant_eye, data = students) dom.eye.freq ## dominant_eye ## l r ## 48 106 TIP: Take note of the syntax in the arguments provided to the xtabs function. We’ll return to this later. We see that there are 2 categories (or “levels”) “l” and “r” representing left and right; this was also shown by the skim function earlier. There are 48 and 106 observations (students) in those respective categories. To show the relative frequency distribution for the dominant_eye variable, use the prop.table function on the dom.eye.freq object. Again, we’ll assign the output to an object, here called dom.eye.prop: dom.eye.prop &lt;- prop.table(dom.eye.freq) dom.eye.prop ## dominant_eye ## l r ## 0.3116883 0.6883117 You can convert these relative frequencies to percentages by multiplying them by 100: 100 * dom.eye.prop ## dominant_eye ## l r ## 31.16883 68.83117 2.4.1.1 OPTIONAL Or for those that are able to use the tigerstats package, you can use the rowPerc function to convert the raw frequencies to percentages: rowPerc(dom.eye.prop) 2.4.2 Create a sorted frequency table When there are more than 2 categories in the variable of interest, you will need to sort the frequencies in decreasing order. There are several steps to this, which we’ll demonstrate using the birds dataset. use the xtabs function to create a frequency table use the sort function to sort the resulting frequencies across categories use the data.frame function to create a data frame that stores the properly sorted frequencies rename the variables in the data frame show the resulting table bird.table &lt;- xtabs(~ type, data = birds) # create frequency table bird.table.sort &lt;- sort(bird.table, decreasing = TRUE) # sort the frequencies in decreasing order bird.df &lt;- data.frame(bird.table.sort) # create a data frame names(bird.df) &lt;- c(&quot;Birdtype&quot;, &quot;Frequency&quot;) # rename variables bird.df # show the final table ## Birdtype Frequency ## 1 Waterfowl 43 ## 2 Predatory 29 ## 3 Shorebird 8 ## 4 Songbird 6 There we go! A frequency table that is appropriately sorted. We’ll use the bird.table.sort object later for graphing too. 2.4.2.1 Alternative approach An alternative and more efficient way to create a sorted frequency table uses the tabyl function from the janitor package, along with the %&gt;% or “pipe” operator, which is loaded with the dplyr package. This operator allows you to string together a series of commands, without having to create intermediate output objects. We also make use of the arrange and desc functions from the dplyr package. Let’s see the code, and explain after: birds %&gt;% tabyl(type) ## type n percent ## Predatory 29 0.33720930 ## Shorebird 8 0.09302326 ## Songbird 6 0.06976744 ## Waterfowl 43 0.50000000 We first tell R which object we’re going to use for our subsequent operations. Here, the birds dataframe object. We then use the %&gt;% operator to tell it that we have further functions to come! The next line of code uses the tabyl function from the janitor package, and tells R which categorical variable (type) to tabulate frequencies for. What we get is a table with 3 columns. The first column contains the unique categories for the type variable. The second column provides the frequency of observations in each category, and the last column is the proportion of observations in the categories (contrary to what is indicated by the “percent” heading!). If there had been missing values in the type variable, you would see another row in the table indicating the frequency of “NA” values. But note that the table isn’t sorted! To sort the table in decreasing order of frequency, we add another line of code after another %&gt;%, and use the arrange function in conjunction with the desc function as follows: birds %&gt;% tabyl(type) %&gt;% arrange(desc(n)) ## type n percent ## Waterfowl 43 0.50000000 ## Predatory 29 0.33720930 ## Shorebird 8 0.09302326 ## Songbird 6 0.06976744 The desc function is operating on the “n” column in the output table from the preceding tabyl, and suffice it to say it works with the arrange function to sort the frequencies. 2.4.3 Creating a bar chart We use a bar chart to visualize the frequency distribution for a single categorical variable. Here we’ll use the ggplot approach with its geom_bar function to create a bar chart. To produce the bar chart, we need to produce a summary frequency table first. So let’s get this from our tabyl script above. Here we’ll assign the sorted frequency table to a dataframe called “bird.type.sort”: bird.type.sort &lt;- birds %&gt;% tabyl(type) %&gt;% arrange(desc(n)) Now we can use this to create a barchart. Let’s provide the code first, and explain after. ggplot(data = bird.type.sort, mapping = aes(x = reorder(type, n), y = n)) + geom_bar(stat = &quot;identity&quot;) + ylab(&quot;Frequency&quot;) + xlab(&quot;Bird type&quot;) + coord_flip() + theme_bw() All figures produced using the ggplot2 package start with the ggplot function. Then the following arguments: the data frame or tibble that holds the data (“data = students”) an “aes” argument, within which one specifies the variables to be plotted; here we’re plotting the frequencies from the “n” variable as the “y” variable, and the “type” variable as the “x” variable. To ensure the proper sorting of the bars, we use the reorder function, telling R to reorder the type categories according to the frequencies in the n variable then there’s a plus sign to tell ggplot we’re not done yet with our graph - there are more functions coming then the type of graph, which uses a function starting with “geom”; here we want a bar chart, hence geom_bar the geom_bar function has its own argument: “stat = ‘identity’” tells it just to make the height of the bars equal to the values provided in the “y” variable, here n. the x-axis label the y-axis label the “coord_flip()” function tells it to rotate the graph horizontally then the “theme_bw” function indicates we want a simple black-and-white theme There you have it: a ggplot version of a bar chart! 2.4.4 Calculating descriptive statistics for a categorical variable The proportion is the most important descriptive statistic for a categorical variable. It measures the fraction of observations in a given category within a categorical variable. For example: what proportion of the BIOL202 class has a left dominant eye? The proportion of students that have a left dominant eye is the same as the relative frequency of students in the class that have a left dominant eye. Earlier, using the students dataset, we learned how to show the relative frequencies of students with left versus right dominant eyes in the class using the prop.table function: dom.eye.freq &lt;- xtabs(~ dominant_eye, data = students) dom.eye.prop &lt;- prop.table(dom.eye.freq) dom.eye.prop ## dominant_eye ## l r ## 0.3116883 0.6883117 As shown above, the proportion of students that have left dominant eye is 0.3116883. Proportions always fall between 0 and 1. We can also get this from our table we produced with the tabyl function; the last column of the table provides the relative frequencies, a.k.a. proportions, within each category (even though it says “percent”): bird.type.sort ## type n percent ## Waterfowl 43 0.50000000 ## Predatory 29 0.33720930 ## Shorebird 8 0.09302326 ## Songbird 6 0.06976744 "],["visualizing-and-describing-a-single-numeric-variable.html", "2.5 Visualizing and describing a single numeric variable", " 2.5 Visualizing and describing a single numeric variable 2.5.1 Displaying the frequency distribution for one numerical variable We start by examining the frequency distribution of the variable of interest, which is the number of occurrences (cases) of all values in the data. In this case, the data are numerical. With numerical variables, such as the height_cm variable in the students dataset, it typically does not make sense to tabulate each unique value in the data (as we do with categorical variables) because there may be many, many values with only a single occurrence. Instead, intervals are created, and and the number of occurrences of values within each interval is tallied. It is relatively uncommon in practice to report a frequency table for a numeric variable. Much more common is to proceed directly to graphically displaying the frequency distribution using a histogram. 2.5.2 Creating a histogram A histogram uses the area of rectangular bars to display the frequency distribution (or relative frequency distribution) of a numerical variable. We’ll use ggplot2 to create a histogram. Please do work through the material below, as it will help you understand the overall ggplot approach. We won’t be going into ggplot2 functionality in too much detail in the course tutorials, so if you’re curious, I recommend you check out this tutorial. Specifically, it helps explain the “grammar of graphics” behind the syntax of ggplot. We’ll give the code first, then explain below: ggplot(data = students, aes(x = height_cm)) + geom_histogram(binwidth = 5, color = &quot;black&quot;, fill = &quot;lightgrey&quot;) + xlab(&quot;Height (cm)&quot;) + ylab(&quot;Frequency&quot;) + theme_bw() The syntax follows what was seen above when creating a bar chart. Here we have only an “x” variable, height_cm. The geom_histogram function has its own arguments: - what bin width (interval) should we use for lumping the height data into? You may need to adjust this with trial and error, and you could actually use the hist function (see above) to see what bin width it used… we see that it used 5cm as the bid width, so that’s what we used here - what “color” we want the outlines of each bar in the histogram to be - what “fill” colour we want the bars to be Voila! Your first ggplot histogram! We can also assign the output from the ggplot function to an object, as so: height.hist &lt;- ggplot(data = students, aes(x = height_cm)) + geom_histogram(binwidth = 5, color = &quot;black&quot;, fill = &quot;lightgrey&quot;) + xlab(&quot;Height (cm)&quot;) + ylab(&quot;Frequency&quot;) And then we can add more functions with the “+” sign, and see the result: height.hist.bw &lt;- height.hist + theme_bw() height.hist.bw 2.5.3 Interpreting and describing histograms Frequency distributions for numerical variables can take on a variety of shapes, as shown in the following display of histograms: Use the image above as a guide on how to describe a histogram. Note that the asymmetric distribution displayed above is skewed left. Things to note in your description: outliers - are there observations (bars) showing up far from the others? multiple modes (as in the “bimodal” example above) is it symmetric? is it roughly bell-shaped? Typically your histogram and its description would be accompanied by descriptive statistics (see below). 2.5.4 Calculating descriptive statistics for a numerical variable When describing a numeric variable, calculate and report the mean and standard deviation as measures of centre and spread, respectively If the frequency distribution is roughly symmetric and does not have any obvious outliers, the mean and the standard deviation are the preferred measures of centre and spread If the frequency distribution is asymmetric and / or has outliers, the median and the inter-quartile range (IQR) are the preferred measures of centre and spread, and in this case, one often sees these reported in addition to the mean and standard deviation 2.5.4.1 Introducing the summarise function The dplyr package has a handy summarise (equivalently summarize) function for calculating descriptive statistics. Here, let’s calculate the mean height of students first: summarise(students, mean(height_cm, na.rm = T)) ## mean(height_cm, na.rm = T) ## 1 171.9712 We first tell it the dataframe or tibble to use for calculations, here students. Then we simply use the standard functions that come with the base R, here the mean function. The “na.rm = T” argument ensures that if there are any missing values (NA values),they are removed for the calculation. This must be done for each of the descriptive statistics functions. Notice that the output from the above code is rather untidy: it returns the entire function text above the resulting number. We can fix that, as shown below. summarise(students, mean.ht = mean(height_cm, na.rm = T)) ## mean.ht ## 1 171.9712 What we’ve done here is created a new variable, called “mean.ht,” to hold the output from the mean function. Now, we typically wish to report multiple descriptive statistics, say, the mean and the standard deviation. To do this, we can include more than one function as arguments to the summarise function: summarise(students, mean.ht = mean(height_cm, na.rm = T), sd.ht = sd(height_cm, na.rm = T) ) ## mean.ht sd.ht ## 1 171.9712 10.02728 IMPORTANT: here we have wrapped the code across 4 lines, so as to keep it organized and legible. Notice that there’s a comma at the end of the first two lines: this tells R that there are more arguments coming for the main function. We stop providing commas once we’re done providing arguments, and we can close up the last parenthesis. Now let’s calculate the mean, median, variance, standard deviation, and IQR of height_cm: summarise(students, mean.ht = mean(height_cm, na.rm = T), median.ht = median(height_cm, na.rm = T), variance.ht = var(height_cm, na.rm = T), sd.ht = sd(height_cm, na.rm = T), iqr.ht = IQR(height_cm, na.rm = T), count.ht = n(), count.missing.vals = naniar::n_miss(height_cm)) ## mean.ht median.ht variance.ht sd.ht iqr.ht count.ht count.missing.vals ## 1 171.9712 171.475 100.5463 10.02728 15 154 0 This is an important piece of information to include in your data description, because one needs to know how many observations went into calculating the descriptive statistics. It is also crucial to report this number in figures. For example: Figure 2.1: Fig. 1: Histogram of height for 154 students "],["list-of-functions-and-the-source-packages-used-in-tutorial.html", "2.6 List of functions (and the source packages) used in tutorial", " 2.6 List of functions (and the source packages) used in tutorial Getting started: read.csv url library Data frame structure: names head glimpse (dplyr) str skim (skimr) Frequency tables: xtabs prop.table Graphs: ggplot (ggplot2) geom_bar (ggplot2) geom_histogram (ggplot2) theme_bw (ggplot2) Descriptive stats: summarise (dplyr) mean median var sd IQR sum "]]
