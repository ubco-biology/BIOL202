# Comparing means among two groups {#compare_two_means}

```{r echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "html")
```

**Tutorial learning objectives**

* Learn about paired and two-sample study designs for comparing the mean of a numeric response variable among two categories of a categorical variable (i.e. two groups)
* Learn about the paired _t_-test for testing a hypothesis about the difference between means in a paired design ($d$) 
* Learn about the two-sample _t_-test for testing a hypothesis about the difference between two population means ($\mu_1 - \mu_2$)
* Learn the assumptions of the paired and two-sample *t*-tests
* Learn how to calculate an exact confidence interval for the difference between two means 
* Learn the confidence interval approach for testing the plausibility of a hypothesized value for $\mu_1 - \mu_2$

## Load packages and import data {#twomean_packages_data}

Load the `tidyverse`, `knitr`, `naniar`, `dlookr`, `car`, `skimr`, and `janitor` packages: 

```{r singlenum_packages2, warning = FALSE}
library(tidyverse)
library(knitr)
library(naniar)
library(janitor)
library(skimr)
library(car)
library(dlookr)
```

The following datasets are required: 

* the "blackbird" dataset.  These are the data associated with Example 12.2 in the text (page 330)
* the "students" dataset, describing characteristics of students from BIOL202 from several years back

```{r}
blackbird <- read_csv("https://raw.githubusercontent.com/ubco-biology/BIOL202/main/data/blackbird.csv")
students <- read_csv("https://raw.githubusercontent.com/ubco-biology/BIOL202/main/data/students.csv")
```

## Paired *t*-test

We'll use the `blackbird` dataset for this example.  

For 13 red-winged blackbirds, measurements of antibodies were taken before and after implantation with testosterone.  Thus, the same bird was measured twice. Clearly, these measurements are not independent, hence the need for a "paired" _t_-test.  

Let's first have a look at the `blackbird` dataset:

```{r seeblackbird}
blackbird 
```

The data frame has 26 rows, and includes 3 variables, the first of which "blackbird" simply keeps track of the individual ID of blackbirds.  

The response variable of interest, "Antibody" represents antibody production rate measured in units of natural logarithm (ln) 10^{-3} optical density per minute (ln[mOD/min]).  

The factor variable `time` that has two levels: "After" and "Before".  

These data are stored in **tidy format**, which, as you've [learned](https://ubco-biology.github.io/Procedures-and-Guidelines/tidy-data.html), is the ideal format for storing data. 

Sometimes you may get data in **wide format**, in which case, for instance, we would have a column for the "Before" antibody measurements and another column for the "After" measurements.  

**It is always preferable** to work with long-format (tidy) data.  

Consult the following [webpage](http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/) for instructions on using the `tidyr` package for converting between wide and long data formats.  

With our data in the preferred long format, we can proceed with our hypothesis test, but because the hypothesis focuses on the _differences_ in the paired measurements, we need to calculate those first!   

### Calculate differences {#calc_diffs}

Let's remind ourselves how the data are stored: 

```{r seeblack2}
blackbird
```

We'll use, for the first time, the `pivot_wider` function from the `dplyr` package (which is loaded as part of the `tidyverse`).

The `pivot_wider` function essentially takes data stored in long format and converts it to wide format.

Here's the code, then we'll explain after:

```{r}
blackbird.diffs <- blackbird %>%
  pivot_wider(names_from = time, values_from = Antibody) %>%
  mutate(diffs = After - Before)
```

In the preceding chunk, we: 

* create a new object "blackbird.diffs" to hold our data
* the `pivot_wider` function takes a categorical (grouping) variable "names_from" and creates new columns, one for each unique category; it also takes a "values_from" variable; thus, in our case, we get 2 new columns (because there are 2 categories to the "time" variable: Before and After), and the values placed in those columns are the corresponding values of "Antibody".
* we then create a new variable "diff" that equals the values in the newly created "After" variable minus the values in the "Before" variable.

<div class="note">
**TIP:**
In the blackbird example we have "Before" and "After" measurements of a variable, and we calculated the _difference_ as "$After - Before$", as this is a logical way to do it. It doesn't really matter which direction you calculate the difference, but just be aware that you need to make clear how it was calculated, so that your interpretation is correct.
</div>

Let's have a look at the result:

```{r see_new_blackbird}
blackbird.diffs
```

We can see that some of the `diffs` values are negative, and some are positive.  These would of course be switched in sign if we had calculated the differences as "$Before - After$". 

In any case, this is the new tibble and variable "diffs" that we'll use for our hypothesis test!

### Hypothesis statement {#paired_Htest}

The hypotheses for this paired _t_-test focus on the mean of the *differences* between the paired measurements, denoted by $\mu_d$:  

H~0~: The mean change in antibody production after testosterone implants was zero ($\mu_d = 0$).  
H~A~: The mean change in antibody production after testosterone implants was not zero ($\mu_d \neq 0$).  

Steps to a hypothesis test:  

* We'll use an $\alpha$ level of 0.05.  
* It is a two-tailed alternative hypothesis  
* We'll visualize the data, and interpret the output
* We'll use a paired *t*-test test to test the null hypothesis, because we're dealing with "before and after" measurements taken on the same individuals, and drawing inferences about a population mean $\mu_d$ using sample data  
* We'll check the assumptions of the test (see below)
* We'll calculate our test statistic
* We'll calculate the *P*-value associated with our test statistic
* We'll calculate a 95% confidence interval for the mean difference
* We'll provide a good concluding statement that includes a 95% confidence interval for the mean difference

### A graph to accompany a paired *t*-test {#graph_paried}     

The best way to visualize the data for a paired *t*-test is to create a **histogram** of the calculated *differences* between the paired observations.

```{r fig.width = 4, fig.height = 3, fig.cap = "Histogram of the differences in antibody production rate before and after the testosterone treatment"}

blackbird.diffs %>% 
  ggplot(aes(x = diffs)) +
  geom_histogram(binwidth = 0.1, boundary = -0.3, 
                 color = "black", fill = "lightgrey",) +
  xlab("Difference in antibody production rate (after - before) (ln[mOD/min]) 10^-3") +
  ylab("Frequency") +
  theme_bw()
```

With such a small sample size (13), the histogram is not particularly informative. But we do see most observations are just above zero.  

**OPTIONAL**

Another optional but nice way to visualize paired data is using a paired plot. 

```{r fig.width = 4, fig.height = 3, fig.cap = "Paired plot of antibody production rate before and after the testosterone treatment"}

blackbird %>%
  ggplot(aes(x = time, y = Antibody)) +
  geom_point(shape = 1, size = 1.5) +
  geom_line(aes(group = blackbird), color = "grey") +
  theme_bw()
```

**OPTIONAL**

Notice that the "After" group is plotted on the left, which is a bit counter-intuitive.  We could optionally change that by changing how R recognizes the "order" of the "time" variable:

```{r eval = F}
blackbird$time <- ordered(blackbird$time, levels = c("Before", "After"))
```

Then repeat the code above to create the paired plot. 

### Assumptions of the paired *t*-test {#assump_paried}

The assumptions of the paired *t*-test are the same as the assumptions for the one-sample *t*-test, except they pertain to the *differences*:  

* the sampling units are randomly sampled from the population
* the _differences_ have a normal distribution in the population (each group of measurements need not be normally distributed) 

As instructed in the [checking assumptions](#checknorm_assum) tutorial, we should use a normal quantile plot to visually check the normal distribution assumption.

```{r fig.width = 4, fig.height = 3, fig.cap = "Normal quantile plot of the differences in antibody production rate before and after the testosterone treatment (ln[mOD/min]) 10^-3."}

blackbird.diffs %>%
  ggplot(aes(sample = diffs)) +
  stat_qq(shape = 1, size = 2) +
  stat_qq_line() +
  xlab("Normal quantile") +
  ylab("Antibody production (ln[mOD/min]) 10^-3") +
  theme_bw()
```

We see that most of the lines are close to the line, with one point near the top right that is a bit off...

A reasonable statement would be: 

> "The normal quantile plot shows that the data generally fall close to the line (except perhaps the highest value), indicating that the normality assumption is reasonably met." 

But if you're feeling uncertain, we can follow this with a **Shapiro-Wilk Normality Test**, which tests the null hypothesis that the data are sampled from a normal distribution:    

```{r normtest_paired}
shapiro.result <- blackbird.diffs %>%
  dlookr::normality(diffs)
shapiro.result
```

Given that the *P*-value is large (and much greater than 0.05), there is no reason to reject the null hypothesis. Thus, our normality assumption is met.  

When testing the normality assumption using the Shapiro-Wilk test, there is no need to conduct all the steps associated with a hypothesis test. Simply report the results of the test (the test statistic value and the associated *P*-value).  

For instance: 

>"A Shapiro-Wilk test revealed no evidence against the assumption that the data are drawn from a normal distribution (*W* = `r round(shapiro.result$statistic,2)`, *P*-value = `r round(shapiro.result$p_value,3)`)."  

### Conduct the test {#conduct_paired}

We can conduct a **paired t-test** in two different ways:  

* conduct a one-sample *t*-test on the _differences_ using the `t.test` function and methods you learned in a [previous tutorial](#onesamp_t_test).

* conduct a paired *t*-test using the `t.test` function and the argument `paired = TRUE`.

**(1) One-sample *t*-test on the differences**

Let's proceed with the test as we've [previously learned](#onesamp_t_test).

Here we make sure to set the null hypothesized value of "mu" to zero in the argument for the `t.test` function:

```{r first_ttest2}
blackbird.ttest <- blackbird.diffs %>%
  select(diffs) %>%
  t.test(mu = 0, alternative = "two.sided", conf.level = 0.95) 
```

Now have a look at the result:

```{r first_ttest3}
blackbird.ttest
```

The observed *P*-value for our test is larger than our $\alpha$ level of 0.05.  We therefore fail to reject the null hypothesis. 

**(2) Paired *t*-test**

Here we use a method that relies on the data being stored in tidy (long) format, and assuming the order of the observations for each pair is correct.  For instance, this is the case for our "blackbird" tibble. Specifically, birds 1 through 13 are ordered the same within each of the "After" and "Before" groups.  This is crucial for this implementation of the paired *t*-test.

Here's the code for running a paired *t*-test on tidy (long) format data:

```{r paired_t_tidy}
blackbird.paired.ttest <- blackbird %>% 
  t.test(Antibody ~ time, data = ., paired = TRUE, conf.level = 0.95)
```

Here's an explanation: 

* we create a new object "blackbird.paried.ttest" to store our results in
* we run the `t.test` function with the arguments as follows: 
  + we use a formula syntax to specify Y ~ X, like we did when learning the [Levene's Test of equal variance](#levenetest); In this case, we have our numerical response variable (Y) "Antibody", then the "~" symbol, then the explanatory categorical variable (X) "time".
  + **NEW**: we have an argument "data = .", which tells the `t.test` function that whatever data was passed to it from the preceding line is what will be used
  + we have the "paired = TRUE" argument, telling the function that this is a paired design
  + finally we use "conf.level = 0.95" which corresponds to an $\alpha = 0.05$
  
Let's look at the result:

```{r pairedresults}
blackbird.paired.ttest
```

The output is identical to what we got when we applied a 1-sample *t*-test on the differences!

### Concluding statement {#concl_paired}

Here's an example of a reasonable concluding statement, and this can apply for either of the two methods used above (note that in either case we call the test a "paired *t*-test, even if we used the one-sample *t*-test on the differences):

> We have no reason to reject the null hypothesis that the mean change in antibody production after testosterone implants was zero (paired _t_-test; _t_ = `r round(blackbird.paired.ttest$statistic,2)`; df = `r blackbird.paired.ttest$parameter`; _P_ = `r round(blackbird.paired.ttest$p.value,3)`; 95% confidence interval for the difference: `r round(blackbird.paired.ttest$conf.int[1], 3)` $< \mu_d <$ `r round(blackbird.paired.ttest$conf.int[2], 3)`). 

## Two sample *t*-test {#twosamp_ttest}

Have a look at the `students` dataset:  

```{r}
students %>%
  skim_without_charts()
```

These data include measurements taken on 154 students in BIOL202 a few years ago.  

We'll use the "height" and "Dominant_eye" variables for this section. 

**OPTIONAL** 

Note that the categories in the `Dominant_eye` variable are "l" and "r", denoting "left" and "right".

We can use the `unique` function to tell us all unique values of a categorical variable:

```{r}
students %>% 
  select(Dominant_eye) %>%
  unique()
```
Let's change these to be more informative, "Left" and "Right". 

We can do this with the `recode_factor` function from the `dplyr` package (part of the `tidyverse`), in conjunction with the familiar `mutate` function used to create a new variable (though here we're just over-writing an existing variable):

```{r}
students <- students %>%
  mutate(Dominant_eye = recode_factor(Dominant_eye, r = "Right", l = "Left"))
```

### Hypothesis statement {#twosamp_hyp}

H~0~: Mean height is the same among students with left dominant eyes and right dominant eyes ($\mu_L = \mu_R$).  
H~A~: Mean height is not the same among students with left dominant eyes and right dominant eyes ($\mu_L \ne \mu_R$). 

Steps to a hypothesis test:  

* We'll use an $\alpha$ level of 0.05.  
* It is a two-tailed alternative hypothesis  
* We'll provide a table of descriptive statistics for each group
* We'll visualize the data, and interpret the output
* We'll use a 2-sample *t*-test test to test the null hypothesis, because we're dealing with numerical measurements taken on independent within two independent groups, and drawing inferences about population means $\mu$ using sample data  
* We'll check the assumptions of the test (see below)
* We'll calculate our test statistic
* We'll calculate the *P*-value associated with our test statistic
* We'll calculate a 95% confidence interval for the difference ($\mu_L - \mu_R$)
* We'll provide a good concluding statement that includes a 95% confidence interval for the mean difference ($\mu_L - \mu_R$)  

### A table of descriptive statistics {#stats_2samp} 

When we are analyzing a numeric response variable in relation to a categorical variable with two or more categories, it's good practice to provide a table of summary (or "descriptive") statistics (including confidence intervals for the mean) for the numeric variable grouped by the categories.

In a previous [tutorial](#desc_numeric_var_cat) we learned how to calculate descriptive statistics for a numeric variable grouped by a categorical variable.  In another [tutorial](#conf_precision) we also learned how to calculate confidence intervals for a numeric variable.

We've also learned that the `t.test` function returns a confidence interval for us.

Let's use all these skills to generate a table of summary statistics for the "height_cm" variable, grouped by "Dominant_eye":

```{r conf_table_2samp}
height.stats <- students %>%
  group_by(Dominant_eye) %>%
  summarise(
    Count = n() - naniar::n_miss(height_cm),
    Count_NA = naniar::n_miss(height_cm), 
    Mean = mean(height_cm, na.rm = TRUE),
    SD = sd(height_cm, na.rm = TRUE),
    SEM = SD/sqrt(Count),
    Low_95_CL = t.test(height_cm, conf.level = 0.95)$conf.int[1],
    Up_95_CL = t.test(height_cm, conf.level = 0.95)$conf.int[2]
  )
```

The only unfamiliar code in the preceding chunk is the last two lines:

* we use the `t.test` function to calculate the lower and upper confidence limits. Specifically:
  + after the closing parenthesis to the `t.test` function, we include "$conf.int[1]", and this simply extracts the first value (lower limit) of the calculated confidence limits from the `t.test` output
  + we do the same for the upper confidence limit, but this time we include "$conf.int[2]"

Now let's have a look at the table, using the `kable` function to produce a nice table.

**NOTE** here I am rotating the table so that it fits on the page. To do this, use the `t` function as follows:

```{r descstats_height}
kable(t(height.stats), digits = 4)
```

It is best to NOT rotate the table, but it is fine to do so if your table goes off the page!  

We'll learn a better way to get around this later.

### A graph to accompany a 2-sample *t*-test {#graph_2samp} 

We learned in an earlier [tutorial](#numeric_vs_cat) that we can use a stripchart, violin plot, or boxplot to visualize the association between a numerical response variable and a categorical explanatory variable. Better yet, we can do the [combined violin & boxplot](#bestplot). 

Here we want to visualize height in relation to dominant eye (Left or Right). We can use the information provided in our descriptive stats table to get the sample sizes for the groups (which we need to report in the figure heading). 

```{r fig.width = 3, fig.height = 4, fig.cap = "Violin and boxplot of the heights of students with right (n = 106) and left (n = 48) dominant eyes.  Boxes delimit the first to third quartiles, bold lines represent the group medians, and whiskers extend to 1.5 times the IQR. Points beyond whiskers are extreme observations."}

students %>% 
  ggplot(aes(x = Dominant_eye, y = height_cm)) +
  geom_violin() +
  geom_boxplot(width = 0.1) + 
  geom_jitter(colour = "grey", size = 1, shape = 1, width = 0.15) +
  xlab("Dominant eye") +
  ylab("Height (cm)") +
  theme_bw()
```

**Interpretation**

> We can see in the preceding figure that heights are generally similar between students with left dominant eyes and those with right dominant eyes.  However, it appears that the spread of the heights is greater among students with right dominant eyes.  We will need to be careful about the equal-variance assumption for the 2-sample *t*-test. 

### Assumptions of the 2-sample *t*-test {#twosamp_assump}

The assumptions of the 2-sample *t*-test are as follows:  

* each of the two samples is a random sample from its population
* the numerical variable is normally distributed in each population
* the variance (and thus standard deviation) of the numerical variable is the same in both populations  

**Test for normality**  

Now let's check the normality assumption by plotting a normal quantile plot for each group. 

We'll introduce the `facet_grid` function that enables plotting of side-by-side panels according to a grouping variable.  

```{r fig.width = 5, fig.height = 3, fig.cap = "Normal quantile plots of height for students with right (n = 106) or left (n = 48) dominant eyes."}

students %>%
  ggplot(aes(sample = height_cm)) +
  stat_qq(shape = 1, size = 2) +
  stat_qq_line() +
  facet_grid(~ Dominant_eye) +
  xlab("Normal quantile") +
  ylab("Height (cm)") +
  theme_bw()
```

A reasonable statement would be: 

> "The normal quantile plots show that student height is generally normally distributed for students with left or right dominant eyes. There is one observation among the right-dominant eye students that is a bit off the line." 

**Test for equal variances**  

Now we need to test the assumption of equal variance among the groups, using Levene's Test as we learned in the [checking assumptions](#levenetest) tutorial.   

```{r}
height.vartest <- leveneTest(height_cm ~ Dominant_eye, data = students)
height.vartest
```

It uses a test statistic "F", and we see here that the *P*-value associated with the test statistic is larger than 0.05, so we don't reject the implied null hypothesis that the variances are equal. 

We state "A Levene's test showed no evidence against the assumption of equal variance (*F* = `r round(unlist(height.vartest)[3], 2)`; *P*-value = `r round(unlist(height.vartest)[5], 3)`)."

Thus, we'll proceed with conducting the 2-sample *t*-test.  

### Conduct the 2-sample *t*-test {#conduct_2samptest}

We use the `t.test` function again for this test. 

```{r go_2samp}
height.ttest <- students %>%
  t.test(height_cm ~ Dominant_eye, 
         data = ., paired = FALSE, 
         var.equal = TRUE, conf.level = 0.95)
```

The only differences from the implementation used in the paired *t*-test are:

* we used "paired = FALSE"
* we include the "var.equal = TRUE" argument

We again include the argument "data = .", which tells the `t.test` function that whatever data was passed to it from the preceding line is what will be used

We'll learn a bit later what to due when the equal variance assumption is not met.

Let's look at the result:

```{r see_2samp}
height.ttest
```

We see that the test produced a *P*-value greater than $\alpha$, so we fail to reject the null hypothesis.  

Note also that the output includes a **confidence interval** for the _difference_ in group means. We need to include this in our concluding statement.  

### Concluding statement {#concl_2samp}

Here's an example of a concluding statement: 

> On average, students with left dominant eyes are similar in height to students with right dominant eyes (Figure 19.4) (2-sample *t*-test; *t* = `r abs(round(height.ttest$statistic,2))`; df = `r height.ttest$parameter`; *P*-value = `r round(height.ttest$p.value,3)`; 95% confidence interval for the difference in height `r round(height.ttest$conf.int[1], 3)` $< \mu_d <$ `r round(height.ttest$conf.int[2], 3)`).

## When assumptions aren't met {#assumpbad_2samp}

If the **normal distribution assumption** is violated, and you are unable to find a transformation that works (see the [Checking assumptions and data transformations](#assumptions_packages_data) tutorial), then you can try a non-parametric test.

A tutorial on non-parametric tests is under development, but will not be deployed until 2022. Consult chapter 13 in the Whitlock & Schluter text, and this [website](https://whitlockschluter3e.zoology.ubc.ca/RExamples/Rcode_Chapter_13.html#new_methods_on_this_page) for some R examples. 

If the **equal-variance assumption** is violated for the 2-sample *t*-test, then you can set the "var.equal" argument to "FALSE" in the `t.test` function, in which case the function implements a "Welch's *t*-test".

For instance, let's pretend that the height data did not exhibit equal variance among left- and right- dominant eye students, here's the appropriate code:

```{r go_2samp2}
height.ttest.unequal.var <- students %>%
  t.test(height_cm ~ Dominant_eye, 
         data = ., paired = FALSE, 
         var.equal = FALSE, conf.level = 0.95)
height.ttest.unequal.var
```

