# Comparing means among more than two groups {#compare_three_more_means}

```{r echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "html")
```

**Tutorial learning objectives**

* Learn how to analyze a numeric response variable in relation to a single categorical explanatory variable that has more than two groups. In other words, we will learn how to compare the means of more than 2 groups.  
* Learn how to implement all the steps of an <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Analysis-of-variance">**Analysis of Variance** (ANOVA)</a>, which is often the most suitable method for testing the null hypothesis of no difference between the means of more than two groups (i.e. $\mu_1 = \mu_2 = \mu_3 = \mu_i..$)

<div class="note">
It might seem strange that a test designed to compare means among groups is called "Analysis of Variance". The reason lies in how the test actually works, as described in Chapter 15 of the text. 
</div>

* Here we learn **fixed-effects ANOVA** (also called Model-1 ANOVA), in which the different categories of the explanatory variable are predetermined, of direct interest, and repeatable. These methods therefore typically apply to **experimental studies**.  
* When the groups are sampled at random from a larger population of groups, as in most **observational studies**, one should typically use a **random-effects ANOVA** (also called Model-2 ANOVA). Consult the following [webpage](https://whitlockschluter3e.zoology.ubc.ca/RExamples/Rcode_Chapter_15.html) for tutorials on how to conduct various types of ANOVA.
* In this tutorial we're learning about a **One-way ANOVA**, in which there is only one explanatory (categorical) variable
* Learn the assumptions of ANOVA
* Learn appropriate tables and graphs to accompany ANOVA
* Learn how to conduct a **post-hoc** comparison among all pairs of group means: the **Tukey-Kramer post-hoc test**

## Load packages and import data {#anova_packages_data}

Load the `tidyverse`, `knitr`, `naniar`, `car`, `skimr`, and `broom` packages: 

```{r anova_packages, warning = FALSE, message = FALSE}
library(tidyverse)
library(knitr)
library(naniar)
library(skimr)
library(broom)
library(car)
```

For this tutorial we'll use the "circadian.csv" dataset.  These data are associated with Example 15.1 in the text. 

The `circadian` data describe melatonin production in 22 people randomly assigned to one of three light treatments.  

```{r anova_getdata2}
circadian <- read_csv("https://raw.githubusercontent.com/ubco-biology/BIOL202/main/data/circadian.csv")
```

<div class="note">
**TIP:**
When analyzing a numeric response variable in relation to a categorical variable, it is good practice to ensure that the categorical variable is treated as a "factor" type variable by R, and that the categories or "levels" of the factor are ordered in the correct way for the purpose of graphs and / or tables of <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Descriptive-statistics">descriptive statistics</a>. For example, there is often a "control" group (category), and if so, this group should come first in a graph or table.
</div>

Let's follow this practice for the "circadian" dataset. 

If we look at example 15.1 in the text, and the corresponding figure (Fig. 15.1), we see that there should be three treatment groups "Control", "Knees", and "Eyes", in that order.

Let's have a look at the data.

```{r anova_lookdata}
circadian %>%
  skim_without_charts()
```

And also have a look at the tibble itself:

```{r look_circadian}
circadian
```

The data are stored in tidy <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Long-format-data">(long) format</a> - good!

We can see the unique values of the categorical variable as follows:

```{r see_unique}
circadian %>%
  select(treatment) %>%
  unique()
```

**Two important things to notice here**: 

* The categorical variable "treatment" is recognized as a "character" variable ("chr") instead of a "factor" variable, 
* The category names are not capitalized

Let's recode this using the method we previously learned in the [2-sample _t_-test tutorial](#twosamp_ttest), using the `recode_factor` function from the `dplyr` package (loaded as part of the `tidyverse`).

Be sure to provide the variables in the order that you want them to appear in any tables, figures, and analyses.

```{r covert_var}
circadian <- circadian %>%
  mutate(treatment = recode_factor(treatment, control = "Control", knee = "Knee", eyes = "Eyes", ))
```

Have a look:

```{r check_treat}
circadian$treatment
```

OK, so not only have we successfully changed the type of variable to factor, and capitalized the category names, but it turns out that the ordering of the factor "levels" is in the correct order, i.e. consistent with how it's displayed in the text figure in example 15.1.   

Now we're ready to proceed with ANOVA!

## Analysis of variance {#do_the_anova}

**Follow these steps when conducting a <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Hypothesis-testing">hypothesis test</a>:**

* State the <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Null-hypothesis">null</a> and <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Alternative-hypothesis">alternative</a> hypotheses  
* Set an <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Significance-level-($\alpha$)">$\alpha$ level </a> 
* Identify the appropriate test & provide rationale
* Prepare an appropriately formatted table of descriptive statistics for the response variable grouped by the categories of the explanatory variable.  
* Visualize the data with a good graph and interpret the graph
* Assumptions  
  + state the assumptions of the test  
  + use appropriate figures and / or tests to check whether the assumptions of the statistical test are met
  + transform data to meet assumptions if required 
  + if assumptions can't be met (e.g. after <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Data-transformation">transformation</a>), use [non-parametric test](#assumpbad_anova) and repeat steps above 
* Conduct the test, and report the test statistic and associated <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#P-value">_P_-value</a>  
* Calculate and include a <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Confidence-interval">confidence interval</a> (e.g. for *t*-tests) or $R^2$ value (e.g. for ANOVA) when appropriate  
* Optionally, for ANOVA, conduct a "post-hoc" comparison of <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Mean">means</a> using "Tukey-Kramer post-hoc test"
* Draw the appropriate conclusion and communicate it clearly  
* Your concluding statement should refer to an ANOVA table (if required), a good figure, and the $R^2$ value  

**Additional, OPTIONAL steps for ANOVA tests**  

These steps may be warranted depending on the context.  

* An appropriately formatted ANOVA results table (definitely include this for any research projects you're writing up)
* A good figure with results of <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Post-hoc-test">**post-hoc tests**</a> included (if these tests were conducted)   

### Hypothesis statements {#anova_hyps}

The null hypothesis of ANOVA is that the population means $\mu_i$ are the same for all treatments. Thus, for our current example in which melatonin production was measured among treatment groups:  

H~0~: Mean melatonin production is equal among all treatment groups ($\mu_1 = \mu_2 = \mu_3$).  
H~A~: At least one treatment group's mean is different from the others  

**OR**  

H~A~: Mean melatonin production is not equal among all treatment groups.  

We'll set $\alpha = 0.05$.  

We'll use a fixed-effects ANOVA, which uses the $F$ test statistic.  

### A table of descriptive statistics {#stats_anova}

In a previous [tutorial](#desc_numeric_var_cat) we learned how to calculate descriptive statistics for a numeric variable grouped by a categorical variable.  In the [comparing 2 means tutorial](#stats_2samp) we also learned how to use the `t.test` function to calculate confidence intervals for a numeric variable.

Let's use all these skills to generate a table of summary statistics for the "shift" variable, grouped by "treatment":

```{r conf_table_anova_now}
circadian.stats <- circadian %>%
  group_by(treatment) %>%
  summarise(
    Count = n() - naniar::n_miss(shift),
    Count_NA = naniar::n_miss(shift), 
    Mean = mean(shift, na.rm = TRUE),
    SD = sd(shift, na.rm = TRUE),
    SEM = SD/sqrt(Count),
    Low_95_CL = t.test(shift, conf.level = 0.95)$conf.int[1],
    Up_95_CL = t.test(shift, conf.level = 0.95)$conf.int[2]
  )
```

Let's have a look at the result, and we'll use the `kable` function to make the table nicer:

```{r conf_table_anova_now_show}

kable(circadian.stats, digits = 4)
```

### Visualize the data {#anova_graph1}

We are interested in visualizing a numeric response variable in relation to a categorical explanatory variable.  

We learned in an earlier [tutorial](#numeric_vs_cat) that we can use a stripchart, violin plot, or boxplot to visualize a numerical response variable in relation to a categorical variable.  

It is commonplace to use a stripchart for small sample sizes in each group.

We'll use code we learned in an [earlier tutorial](#numeric_vs_cat).

However, because we're now not only describing and visualizing data, but also testing a hypothesis about differences in group means, it is best to add group means and error bars to our stripchart.

The `stat_summary` function from the `ggplot2` package is what provides the error bars and group means:

```
?stat_summary
```

Here's the code:

```{r stripanova, fig.cap = "Stripchart of phase shifts in the circadian rhythm of melatonin production in 22 participants of an experiment. Solid circles denote group means, and bars +/- one standard error", fig.width = 4, fig.height = 4.5}

circadian %>%
  ggplot(aes(x = treatment, y = shift)) +
  geom_jitter(colour = "darkgrey", size = 3, shape = 1, width = 0.1) +
  stat_summary(fun.data = mean_se, geom = "errorbar", 
    colour = "black", width = 0.1, 
    position = position_nudge(x = 0.15)) +
  stat_summary(fun = mean, geom = "point", 
    colour = "black", size = 3, 
    position = position_nudge(x = 0.15)) +
  xlab("Light treatment") + 
  ylab("Shift in circadian rhythm (h)") + 
  theme_classic()
```

We've added two sets of `stat_summary` functions, one for adding the group mean, and one for adding the error bars.

* The argument "fun = mean_se" adds the <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Standard-error">standard error</a> of the group means
* the "geom = 'errorbar'" tells ggplot to use an error bar format
* the "position = position_nudge(x = 0.15)" tells ggplot to nudge the error bar off to the side a bit, so it doesn't obscure the data points
* the next `stat_summary` function is the same, but this time for the group means.

Clearly there is no difference between the control and knee treatment groups, but we'll have to await the results of the ANOVA to see whether the mean of the "eyes" group is different.  

### Assumptions of ANOVA {#assump_anova}

The <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Assumptions">assumptions</a> of ANOVA are:  

* The measurements in every group represent a random sample from the corresponding population (**NOTE**: for an experimental study, the assumption is that subjects are randomly assigned to treatments)  
* The response variable has a normal distribution in each population 
* The <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Variance">variance</a> of the response variable is the same in all populations (called the "homogeneity of variance" assumption) 

* * *

**Test for normality**  

The sample sizes per group are rather small, so graphical aids such as histograms or normal quantile plots will not be particularly helpful.  

Instead, let's rely on the fact that (i) the strip chart in Figure 2 does not show any obvious outliers in any of the groups, and (ii) the central limit theorem makes ANOVAs quite robust to deviations in normality, especially with larger sample sizes, but even with relatively small sample sizes such as these. So, we'll proceed under the assumption that the measurements are normally distributed within the three populations.  

* * *

**Test for equal variances**  

Now we need to test the assumption of equal variance among the groups, using Levene's Test as we learned in the [checking assumptions](https://ubco-biology.github.io/BIOL202/checking-assumptions-and-data-transformations.html) tutorial.   

```{r testvar}
variance.check <- leveneTest(shift ~ treatment, data = circadian)
variance.check
```

We see that the *P*-value for the test is much greater than 0.05, so the null hypothesis of equal variance is **not** rejected. There is no evidence against the assumption that the variances are equal.  

A reasonable statement: 

"A Levene's test showed no evidence against the assumption of equal variance (*F* = `r round(unlist(variance.check)[3], 2)`; *P*-value = `r round(unlist(variance.check)[5], 3)`)."

* * *

**IF assumptions are not met** 

A later [section](#assumpbad_anova) discusses what to do if assumptions are NOT met.

### Conduct the ANOVA test {#do_anova1}

There are two steps to conducting an ANOVA in R: 

* Use the `lm` function (from the base package) (it stands for "linear model") to create an object that holds the key output from the test

* Use the `anova` function (from the base package) on the preceding `lm` output object to generate the appropriate output for interpreting the results.   

The `lm` function uses the syntax: Y ~ X.  

Let's do this step first:

```{r conductANOVA}
circadian.lm <- lm(shift ~ treatment, data = circadian) 
```

Next the `anova` step: 

```{r do_anova_step}
circadian.lm.anova <- anova(circadian.lm)
```

Let's have a look at what this produced:

```{r showrawanova}
circadian.lm.anova
```

This is not in the format of a traditional ANOVA table (as described in Chapter 15 of the text): it is missing the "Total" row, and it puts the degrees of freedom (df) column before the Sums of Squares. Also, the column headers could be more informative.  

Nor is the object in "tidy" format.

Optionally, we can use the `tidy` function from the `broom` package to tidy the output as follows:

```{r tidy_anova}
circadian.lm.anova.tidy <- circadian.lm.anova %>%
  broom::tidy()
```

Have a look at the tidier (but still not ideal) output:

```{r}
circadian.lm.anova.tidy
```

#### OPTIONAL: Generate nice ANOVA table {#createanovatable}

Let's look again at the raw output from the `anova` function:

```{r showrawanova2}
circadian.lm.anova
```

In the code chunk below we create a new function called "create.anova.table", which we can use to convert an "anova" object (like the one above) to an appropriately formatted ANOVA table.

When you run this code chunk, it creates the function in your workspace. Once it is created, you can use it.

<div class="note">
You will need to run this chunk to create the function each time you start a new R session. 
**AND** this is a quick-and-dirty function that does **NOT** follow all the best practices in coding!
</div>

```{r create_anova_function}
create.anova.table <- function(intable){
  # first check that input table is of class "anova"
  if(class(intable)[1] != "anova") stop("Input object not of class 'anova'")
  require(tidyverse) # ensure tidyverse is loaded
  require(broom) # ensures broom is loaded
  tidy.intable <- tidy(intable)
# "intable" is a the object from the `anova` output
  temp.anova <- tidy.intable %>%
    select("term", "sumsq", "df", "meansq", "statistic", "p.value")  # reorder columns
  temp.anova <- temp.anova %>%
    rename(Source = term, SS = sumsq, MS = meansq, F = statistic, P_val = p.value) # rename columns
totals <- data.frame(
  Source = "Total",
  df = sum(temp.anova$df),
  SS = sum(temp.anova$SS),
  MS = NA,
  F = NA,
  P_val = NA
)  # calculate totals
  nice.anova.table <- as_tibble(rbind(temp.anova, totals)) # generate table
return(nice.anova.table)
}
```

Let's try out the function, using our original anova table:  

```{r}
nice.anova.table <- create.anova.table(circadian.lm.anova)
```

And present it:
```{r niceanovapdf}
kable(nice.anova.table, digits = 4, 
      caption = "ANOVA table for the circadian rythm experiment.", 
      lable = "niceanovapdf")
```

Nice!

### Calculate $R^2$ for the ANOVA

One measure that is typically reported with any "linear model" like ANOVA is the "variance explained" or <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Coefficient-of-determination-(R<sup>2</sup>)">**coefficient of determination**</a>, denoted $R^2$.  

This value indicates the fraction of the variation in _Y_ that is explained by groups.  

The remainder of the variation ($1 - R^2$) is "error", or variation that is left unexplained by the groups.  

To calculate this we use two steps, and we go back to our original "lm" object we created earlier:

```{r getrsquare}
circadian.lm.summary <- summary(circadian.lm)
circadian.lm.summary$r.squared
```

We'll refer to this value in our concluding statement.

Before we get there, we need to figure out **which group mean(s) differ??**.  

### Tukey-Kramer post-hoc test {#tukey}

As described in Chapter 15 in the text, **planned comparisons** (aka planned contrasts) are ideal and most powerful, but unfortunately we often need to conduct **unplanned comparisons** to assess which groups differ in our ANOVA test. This is what we'll learn here.  

We can guess from our stripchart (Figure \@ref(fig:stripanova)) that it's the "Eyes" treatment group that differs from the others, but we need a formal test.  

We could simply conduct three 2-sample *t*-tests on each of the three pair-wise comparisons, but then we would inflate our **Type-I error rate**, due to multiple-testing.  

The Tukey-Kramer "post-hoc" (unplanned) test adjusts our *P*-values correctly to account for multiple tests.  

For this test we use the `TukeyHSD` function in the base stats package (HSD stands for "Honestly Significant Difference").

```
?TukeyHSD
```

The one catch in using this function is that we need to re-do our ANOVA analysis using a different function... the `aov` function in lieu of the `lm` function.  This is necessary because the `TukeyHSD` function is expecting a particular object format, which only the `aov` function provides.  

First, let's re-do the ANOVA analysis using the `aov` function, creating a new object.  **NOTE** This is only necessary if you are wishing to conduct the post-hoc Tukey HSD analysis (which we often are).

```{r redo_anova}
circadian.aov <- aov(shift ~ treatment, data = circadian)
```

Now we can pass this object to the `TukeyHSD` function, and use the appropriate confidence level (corresponding to 1 minus alpha):  

```{r doTukey}
circadianTukey <- TukeyHSD(circadian.aov, conf.level = 0.95)
```

And let's make the output `tidy`:

```{r tidytukey}
circadianTukey.tidy <- circadianTukey %>%
  broom::tidy()
```

Have a look a the output:
```{r looktukey}
circadianTukey.tidy
```

Now let's reformat this table for producing a nice output.

```{r reformattukey}
circadianTukey.tidy.table <- circadianTukey.tidy %>%
  select(-c(term, null.value)) %>%  # take away these two columns
  rename(Contrast = "contrast", Difference = "estimate", 
         Conf_low = "conf.low", Conf_high = "conf.high", 
         Adj_Pval = "adj.p.value")
```

Let's see what we made:

```{r seetidytukey}
circadianTukey.tidy.table
```

The output clearly shows the pairwise comparisons and associated _P_-values, **adjusted** for multiple comparisons. It also shows the difference in means, and the lower and upper 95% confidence interval for the differences.

We can see that the mean for the "Eyes" treatment group differs significantly (at $\alpha = 0.05$) from each of the other group means.  

One typically shows these results visually on the same figure used to display the data (here, Figure \@ref(fig:stripanova)).  

### Visualizing post-hoc test results {#vis_tukey}

Here is our original figure, to which we'll add the results of the post-hoc test:

```{r stripanova2, fig.cap = "Stripchart of phase shifts in the circadian rhythm of melatonin production in 22 participants of an experiment. Solid circles denote group means, and bars +/- one standard error", fig.width = 4, fig.height = 4.5}

circadian %>%
  ggplot(aes(x = treatment, y = shift)) +
  geom_jitter(colour = "darkgrey", size = 3, shape = 1, width = 0.1) +
  stat_summary(fun.data = mean_se, geom = "errorbar", 
    colour = "black", width = 0.1, 
    position = position_nudge(x = 0.15)) +
  stat_summary(fun = mean, geom = "point", 
    colour = "black", size = 3, 
    position=position_nudge(x = 0.15)) +
  xlab("Light treatment") + 
  ylab("Shift in circadian rhythm (h)") + 
  theme_classic()
```

To visualize the outcomes of the Tukey-Kramer post-hoc test, we superimpose a text letter alongside (or above) each group in the figure, such that groups sharing the same letter are not significantly different according to the Tukey-Kramer post-hoc test.  

For this we use the `annotate` function, and this requires that we know the coordinates on the graph where we wish to place our annotations.

Based on our stripchart above, it looks like we need to use Y-value coordinates of around 1.1 to place our letters above each group.  **It may take some trial-and-error** to figure this out.

Here's the code, with the `annotate` function added:

```{r stripanovatukey, fig.cap = "Stripchart showing the phase shift in the circadian rhythm of melatonin production in 22 experimental participants given alternative light treatments. Solid circles represent group means, and bars represent +/- one SE. Group means sharing the same letter are not significantly different according to the Tukey-Kramer post-hoc test (family-wise $\\alpha$ = 0.05).", fig.width = 4, fig.height = 4.5}

ggplot(circadian, aes(x = treatment, y = shift)) +
  geom_jitter(colour = "darkgrey", size = 3, shape = 1, width = 0.1) +
  stat_summary(fun.data = mean_se, geom = "errorbar", 
        colour = "black", width = 0.1, 
        position=position_nudge(x = 0.15)) +
  stat_summary(fun = mean, geom = "point", 
        colour = "black", size = 3, 
        position=position_nudge(x = 0.15)) +
  ylim(c(-3.1, 1.2)) +
  annotate("text", x = 1:3, y = 1.1, label = c("a", "a", "b")) +
  labs(x = "Light treatment", y = "Shift in circadian rhythm (h)") + 
  theme_classic()
```

Notice that we have added a line including the `ylim` function, so that we can specify the min and max y-axis limits, ensuring that our annotation letters fit on the graph.

**NOTE**: The chunk option I included to get the figure heading shown above is as follows:  

```
{r fig.cap = "Stripchart showing the phase shift in the circadian rhythm of melatonin production in 22 experimental participants given alternative light treatments. Solid circles represent group means, and bars represent +/- one SE. Group means sharing the same letter are not significantly different according to the Tukey-Kramer post-hoc test (family-wise $\\alpha$ = 0.05).", fig.width = 4, fig.height = 4.5}
```

The "family-wise" $\alpha$ statement means that the Tukey-Kramer test uses our initial $\alpha$ level, but ensures that the <a href="https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Probability">probability</a> of making at least one Type-1 error throughout the course of testing all pairs of means is no greater than the originally stated $\alpha$ level.  

<div class="note">
**TIP:**
Figure \@ref(fig:stripanovatukey) is the kind of figure that should be referenced, typically along with ANOVA table \@ref(tab:niceanovapdf), when communicating your results of an ANOVA. For instance, with the results of the Tukey-Kramer post-hoc tests superimposed on the figure, you can not only state that the null hypothesis is rejected, but you can also state which group(s) differ from which others.
</div>

We are now able to write our truly final concluding statement, below.  

* * *

1. Annotating stripcharts  

Pretend that our post-hoc test showed that the "Knee" group was not different from either the control or the Eyes group.  Re-do the figure above, but this time place an "ab" above the Knee group on the figure. This is how you would indicate that the control and eyes grouped differed significantly from one-another, but neither differed significantly from the Knee group.

### Concluding statement {#anova_conclusion}

With out ANOVA table and final figure in hand, we are ready for the concluding statement: 

> Shifts in circadian rhythm differ significantly among treatment groups (ANOVA; Table \@ref(tab:niceanovapdf); $R^2$ = `r round(circadian.lm.summary$r.squared, 2)`). As shown in Figure \@ref(fig:stripanovatukey), the mean shift among the "Eyes" subjects was significantly lower than both of the other treatment groups.   

## When assumptions aren't met {#assumpbad_anova}

If the **normal distribution assumption** is violated, and you are unable to find a transformation that works (see the [Checking assumptions and data transformations](https://ubco-biology.github.io/BIOL202/checking-assumptions-and-data-transformations.html) tutorial), then you can try a non-parametric test.

A tutorial on non-parametric tests is under development, but will not be deployed until 2023. Consult chapter 13 in the Whitlock & Schluter text, and this [website](https://whitlockschluter3e.zoology.ubc.ca/RExamples/Rcode_Chapter_13.html#new_methods_on_this_page) for some R examples. 

In general, you might find that the "Kruskal-Wallis" rank sum test is a good non-parametric alternative to ANOVA. This can be implemented using the `kruskal.test` function:

```
?kruskal.test
```
